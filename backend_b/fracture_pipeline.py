import cv2
import numpy as np
from pathlib import Path
from PIL import Image, ImageDraw, ImageFont
import os
import torch
from mo import SpineCNN

def crop_each_label_png(image_path, segmentation_path, output_dir):
    # ËØªÂèñÂéüÂõæÂÉèÂíåÂàÜÂâ≤ÂõæÂÉè
    image = cv2.imread(str(image_path), cv2.IMREAD_GRAYSCALE)  # ÂΩ©Ëâ≤
    segmentation = cv2.imread(str(segmentation_path), cv2.IMREAD_UNCHANGED)  # ÂçïÈÄöÈÅìÊ†áÁ≠æÂõæ

    # Ëé∑ÂèñÊâÄÊúâÊ†áÁ≠æÔºàÂøΩÁï•ËÉåÊôØ 0Ôºâ
    unique_labels = np.unique(segmentation)
    unique_labels = unique_labels[unique_labels != 0]

    # ËæìÂá∫Êñá‰ª∂Â§π
    out_img_dir = Path(output_dir) / "images"
    out_seg_dir = Path(output_dir) / "segmentations"
    out_img_dir.mkdir(parents=True, exist_ok=True)
    out_seg_dir.mkdir(parents=True, exist_ok=True)


    for label in unique_labels:
        # ÊâæÂà∞ËØ•Ê†áÁ≠æÁöÑÂùêÊ†á
        coords = np.where(segmentation == label)

        if coords[0].size > 0:
            # ËÆ°ÁÆóËæπÁïåÊ°Ü
            y_min, y_max = np.min(coords[0]), np.max(coords[0])
            x_min, x_max = np.min(coords[1]), np.max(coords[1])

            # Ë£ÅÂâ™ÂéüÂõæÂíåÂàÜÂâ≤Âõæ
            cropped_image = image[y_min:y_max + 1, x_min:x_max + 1]
            cropped_seg = segmentation[y_min:y_max + 1, x_min:x_max + 1]

            # ËΩ¨Êç¢‰∏∫‰∫åÂÄºÊé©Á†ÅÔºàËØ•Ê†áÁ≠æ = 1ÔºåÂÖ∂‰Ωô = 0Ôºâ
            cropped_binary_seg = (cropped_seg == label).astype(np.uint8) * 255  # ‰øùÂ≠ò‰∏∫ÈªëÁôΩÂõæ

            # ÊûÑÂª∫‰øùÂ≠òË∑ØÂæÑ
            out_img_path = out_img_dir / f"{int(label)}.png"
            out_seg_path = out_seg_dir / f"{int(label)}.png"

            # ‰øùÂ≠òË£ÅÂâ™ÁªìÊûú
            cv2.imwrite(str(out_img_path), cropped_image)
            cv2.imwrite(str(out_seg_path), cropped_binary_seg)

    return out_img_dir ,out_seg_dir

def intensity_postprocessing_xray(image: np.ndarray) -> np.ndarray:
    """
    Intensity postprocessing for 2D X-ray image after Gaussian smoothing.
    Normalize to [0, 1] using percentile clipping (1% - 99%).
    """
    p_low, p_high = np.percentile(image, (1, 99))
    image = np.clip(image, p_low, p_high)
    image = (image - p_low) / (p_high - p_low + 1e-8)
    image = np.clip(image, 0.0, 1.0)
    return image.astype(np.float32)


def process_data(image_folder, seg_folder, size=(224, 224)):
    """
    ÊåâÊï∞Â≠óÈ°∫Â∫èÂ§ÑÁêÜ X-ray ÂõæÂÉèÂèäÂØπÂ∫îÂàÜÂâ≤ÂõæÔºåËøîÂõû (N,2,224,224)
    """
    # üîπ ÊåâÊñá‰ª∂Âêç‰∏≠ÁöÑÊï∞Â≠óÊéíÂ∫è
    files = sorted(
        [f for f in os.listdir(image_folder) if f.lower().endswith(".png")],
        key=lambda x: int(os.path.splitext(x)[0])  # '12.png' -> 12
    )

    arrays = []

    for file in files:
        img_path = os.path.join(image_folder, file)
        seg_path = os.path.join(seg_folder, file)

        # --- ÂéüÂõæ ---
        img = Image.open(img_path).convert("L")
        img_np = np.array(img, dtype=np.float32)
        img_np = intensity_postprocessing_xray(img_np)
        img_resized = Image.fromarray((img_np * 255).astype(np.uint8))
        img_resized = img_resized.resize(size, resample=Image.BILINEAR)
        img_resized = np.array(img_resized, dtype=np.float32) / 255.0

        # --- ÂàÜÂâ≤ ---
        seg = Image.open(seg_path).convert("L")
        seg_resized = seg.resize(size, resample=Image.NEAREST)
        seg_resized = np.array(seg_resized, dtype=np.uint8)
        seg_resized = (seg_resized > 127).astype(np.uint8)

        # --- Â†ÜÂè† ---
        arrays.append(np.stack([img_resized, seg_resized], axis=0))

    combined = np.stack(arrays, axis=0)  # (N,2,224,224)
    print(f"‚úÖ Â∑≤ÁîüÊàêÊï∞ÁªÑÔºåshape={combined.shape}")
    return combined


def build_x_and_mask(combined_array, mask_list):
    """ÊûÑÈÄ†ËæìÂÖ•Âº†Èáè x Âíå mask"""
    N = combined_array.shape[0]
    x = np.zeros((24, 2, 224, 224), dtype=np.float32)
    mask = np.zeros(24, dtype=np.float32)

    ptr = 0  # combined_array ÁöÑÊåáÈíà
    for i, m in enumerate(mask_list[:24]):
        if m == 1:
            img = combined_array[ptr]
            resized = np.stack([cv2.resize(img[c], (224, 224)) for c in range(2)], axis=0)
            x[i] = resized
            mask[i] = 1.0
            ptr += 1  # ÁßªÂà∞ combined_array ÁöÑ‰∏ã‰∏ÄÂº†Âõæ

    x = torch.from_numpy(x).unsqueeze(0)   # (1, V, C, H, W)
    mask = torch.from_numpy(mask).unsqueeze(0)  # (1, V)
    return x, mask


def inference_probs(model, combined_array, mask_list, device):
    """ËøîÂõûÊØè‰∏™Ê§éÈ™®ÁöÑÈ¢ÑÊµãÊ¶ÇÁéá (probs)"""
    model.eval()
    x, mask = build_x_and_mask(combined_array, mask_list)
    x = x.to(device)

    with torch.no_grad():
        logits, feat = model(x)
        probs = torch.sigmoid(logits).cpu().numpy().squeeze(0)  # (24,)
    return probs


labelMapping = {}
for i in range(1, 8):
    labelMapping[i] = f"C{i}"
for i in range(8, 20):
    labelMapping[i] = f"T{i - 7}"
for i in range(20, 25):
    labelMapping[i] = f"L{i - 19}"


def fracture_img(id, prob, input_path, output_folder):
    """
    ÁîüÊàêÊ§éÈ™®Ê¶ÇÁéáÂõæÔºö
    - ËæìÂá∫ÂõæÁâáÂÆΩ120pxÔºåÈ´ò150pxÔºåÈÄèÊòéËÉåÊôØ
    - ‰∏äÈÉ®120pxÊîæÁ≠âÊØîÁº©ÊîæÁöÑÂéüÂõæÔºåÂ±Ö‰∏≠
    - ‰∏ãÈÉ®30pxÊîæÊñáÊú¨ 'Ê§éÈ™®Ê†áÁ≠æ Ê¶ÇÁéá'
    """
    # ÊâìÂºÄÂéüÂõæ
    img = Image.open(input_path).convert("RGBA")

    # ÂàõÂª∫ÈÄèÊòéÁîªÂ∏É
    final_w, final_h = 180, 225
    canvas = Image.new("RGBA", (final_w, final_h), (0, 0, 0, 0))

    # ‰∏äÈÉ®ÂÆπÂô®Â∞∫ÂØ∏
    container_w, container_h = 180, 180

    # Á≠âÊØîÁº©ÊîæÂéüÂõæÂà∞ÂÆπÂô®
    img_w, img_h = img.size
    scale = min(container_w / img_w, container_h / img_h)
    new_w, new_h = int(img_w * scale), int(img_h * scale)
    img_resized = img.resize((new_w, new_h), Image.Resampling.LANCZOS)

    # ËÆ°ÁÆóÂ±Ö‰∏≠‰ΩçÁΩÆ
    x_offset = (container_w - new_w) // 2
    y_offset = (container_h - new_h) // 2
    canvas.paste(img_resized, (x_offset, y_offset), img_resized)  # ‰ΩøÁî®Ëá™Ë∫´ alpha

    # ÁªòÂà∂ÊñáÂ≠ó
    draw = ImageDraw.Draw(canvas)
    text = f"{labelMapping.get(id, str(id))}   {prob:.2f}"

    # Â≠ó‰ΩìËÆæÁΩÆ
    font_size = 28
    try:
        font = ImageFont.truetype("arial.ttf", font_size)
    except:
        font = ImageFont.load_default()

    bbox = draw.textbbox((0, 0), text, font=font)
    text_w = bbox[2] - bbox[0]
    text_h = bbox[3] - bbox[1]
    text_x = (final_w - text_w) // 2
    text_y = container_h + (30 - text_h) // 2  # ‰∏ãÈÉ®30pxÂå∫ÂüüÂ±Ö‰∏≠
    draw.text((text_x, text_y), text, fill=(0, 0, 0, 255), font=font)

    # ‰øùÂ≠òÂõæÁâá
    os.makedirs(output_folder, exist_ok=True)
    output_path = os.path.join(output_folder, f"{id}.png")
    canvas.save(output_path)


def fracture(image_path, seg_path, output_dir, points):
    image_folder, seg_folder = crop_each_label_png(image_path, seg_path, output_dir)
    combined_array = process_data(image_folder, seg_folder)
    mask_list = [0] * 24
    for p in points:
        if p['x'] is not None:
            mask_list[p['id'] - 1] = 1

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = SpineCNN().to(device)
    model_path = "./model.pth"
    model.load_state_dict(torch.load(model_path, map_location=device))

    probs = inference_probs(model, combined_array, mask_list, device)

    images_dir = os.path.join(output_dir, "images")
    output_folder = Path(output_dir) / "fracture_images"
    output_folder.mkdir(parents=True, exist_ok=True)
    result = []
    for i, m in enumerate(mask_list):
        if m == 1:
            prob = float(probs[i]) if np.isfinite(probs[i]) else None
            result.append({
                "vertebra_id": i + 1,
                "fracture_prob": prob
            })

            if prob > 0.5:
                input_path = os.path.join(images_dir, f"{i + 1}.png")
                if os.path.exists(input_path):
                    fracture_img(i+1, prob, input_path, output_folder)
                else:
                    print(f"‚ö†Ô∏è ÂõæÁâá‰∏çÂ≠òÂú®: {input_path}")
    return result


# image_path = r"D:\Myproject\pictures\374c6a8d-bd5c-4288-94ad-0504fc5ed177\374c6a8d-bd5c-4288-94ad-0504fc5ed177.png"
# seg_path = r"D:\Myproject\pictures\374c6a8d-bd5c-4288-94ad-0504fc5ed177\374c6a8d-bd5c-4288-94ad-0504fc5ed177_seg1.png"
# task_dir = r'D:\Myproject\pictures\374c6a8d-bd5c-4288-94ad-0504fc5ed177'
# points = [
#   {
#     "id": 1,
#     "x": None,
#     "y": None
#   },
#   {
#     "id": 2,
#     "x": None,
#     "y": None
#   },
#   {
#     "id": 3,
#     "x": None,
#     "y": None
#   },
#   {
#     "id": 4,
#     "x": None,
#     "y": None
#   },
#   {
#     "id": 5,
#     "x": None,
#     "y": None
#   },
#   {
#     "id": 6,
#     "x": None,
#     "y": None
#   },
#   {
#     "id": 7,
#     "x": None,
#     "y": None
#   },
#   {
#     "id": 8,
#     "x": None,
#     "y": None
#   },
#   {
#     "id": 9,
#     "x": 731.2161865234375,
#     "y": 1254.3233642578125
#   },
#   {
#     "id": 10,
#     "x": 753.333740234375,
#     "y": 1460.7532958984375
#   },
#   {
#     "id": 11,
#     "x": 793.8824462890625,
#     "y": 1659.810791015625
#   },
#   {
#     "id": 12,
#     "x": 838.117431640625,
#     "y": 1910.475830078125
#   },
#   {
#     "id": 13,
#     "x": None,
#     "y": None
#   },
#   {
#     "id": 14,
#     "x": None,
#     "y": None
#   },
#   {
#     "id": 15,
#     "x": None,
#     "y": None
#   },
#   {
#     "id": 16,
#     "x": None,
#     "y": None
#   },
#   {
#     "id": 17,
#     "x": None,
#     "y": None
#   },
#   {
#     "id": 18,
#     "x": None,
#     "y": None
#   },
#   {
#     "id": 19,
#     "x": None,
#     "y": None
#   },
#   {
#     "id": 20,
#     "x": None,
#     "y": None
#   },
#   {
#     "id": 21,
#     "x": None,
#     "y": None
#   },
#   {
#     "id": 22,
#     "x": None,
#     "y": None
#   },
#   {
#     "id": 23,
#     "x": None,
#     "y": None
#   },
#   {
#     "id": 24,
#     "x": None,
#     "y": None
#   }
# ]
# fracture(image_path, seg_path, task_dir, points)